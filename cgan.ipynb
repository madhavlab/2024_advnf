{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import data_loader\n",
    "import datetime\n",
    "import pickle\n",
    "import timeit\n",
    "import time\n",
    "import os\n",
    "from utils import *\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "os.makedirs('./cgan_samples', exist_ok=True)\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[3],'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generation(no_samples,temp):\n",
    "    n_zrand = 12   # 6 for 4x4,6x6,8x8 and 12  for 16x16\n",
    "    n_z     = 6\n",
    "    zrand   = tf.random.normal([no_samples,n_zrand],mean=0.0,stddev=1.0,dtype=tf.dtypes.float32)\n",
    "    tz      = tf.cast(tf.repeat(temp,no_samples*n_z),dtype=tf.float32)\n",
    "    tz      = tf.reshape(tz,[no_samples,n_z])\n",
    "    z       = tf.concat([zrand,tz],axis=-1)\n",
    "    samples = generator(z)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_generation_for_all_temp(no_samples,temp_array):\n",
    "    samples = []\n",
    "    for i in temp_array:\n",
    "        samples.append(sample_generation(no_samples,i))\n",
    "    samples = tf.concat(samples,axis=0)\n",
    "    return samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "BATCH_SIZE = 256\n",
    "noise_dim = 18\n",
    "num_classes = 32\n",
    "(l,l) = (16,16) # lattice Size\n",
    "n_z = 6 #No.of temp.Variables\n",
    "n_zrand = 12 #No. of Noise Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_data = np.float32(data_loader.load_data_mh_generated('./data/data/xy_16x16_32_lattices_set1.pkl'))\n",
    "trainset  = []\n",
    "   \n",
    "for i in range(num_classes):\n",
    "    trainset.append(xy_data[10000*i:10000*i+5000])\n",
    "\n",
    "trainset = np.reshape(np.array(trainset),(-1,l,l,1))\n",
    "\n",
    "temp_val = np.linspace(0.05,2.05,num_classes)\n",
    "Temp = np.float32(np.repeat(temp_val,5000))\n",
    "T = np.repeat(Temp,l*l).reshape(-1,l,l,1)\n",
    "T_z = np.repeat(Temp,n_z).reshape(-1,n_z)\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((trainset,T,T_z))\n",
    "training_dataset = training_dataset.shuffle(buffer_size = 1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_generator(): #### 8x8 lattices\n",
    "#     z = keras.Input(shape=(12,))\n",
    "#     hid_x1 = layers.Dense(32,activation='tanh',name='hidden_layer_1')(z)\n",
    "#     hid_x2 = layers.Dense(128,activation='tanh',name='hidden_layer_2')(hid_x1)\n",
    "#     reshape_x3 = layers.Reshape((4,4,8))(hid_x2)\n",
    "#     conv1 = layers.Conv2DTranspose(filters=20,kernel_size=(3,3),strides=1,padding='valid',activation='tanh')(reshape_x3)\n",
    "#     conv_mean = layers.Conv2DTranspose(filters=1,kernel_size=(3,3),strides=1,padding='valid')(conv1)\n",
    "#     conv_scale = layers.Conv2DTranspose(filters=1,kernel_size=(3,3),strides=1,padding='valid')(conv1)\n",
    "#     eps = tf.random.normal(shape = tf.shape(conv_mean),mean =0.0 ,stddev = 1.0, dtype = tf.float32 )\n",
    "#     sample = conv_mean + eps*tf.sqrt(tf.exp(5*conv_scale))\n",
    "#     model = keras.Model(inputs=z,outputs=sample,name='Generator_model')\n",
    "#     model.summary()\n",
    "#     return model\n",
    "\n",
    "def make_generator(): #### 16x16 lattices\n",
    "    z = keras.Input(shape=(18,))\n",
    "    hid_x1 = layers.Dense(32,activation='tanh',name='hidden_layer_1')(z)\n",
    "    hid_x2 = layers.Dense(128,activation='tanh',name='hidden_layer_2')(hid_x1)\n",
    "    reshape_x3 = layers.Reshape((8,8,2))(hid_x2)\n",
    "    conv1 = layers.Conv2DTranspose(filters=8,kernel_size=(3,3),strides=1,padding='valid',activation='tanh')(reshape_x3)\n",
    "    conv2 = layers.Conv2DTranspose(filters=16,kernel_size=(3,3),strides=1,padding='valid',activation='tanh')(conv1)\n",
    "    conv3 = layers.Conv2DTranspose(filters=32,kernel_size=(3,3),strides=1,padding='valid',activation='tanh')(conv2)\n",
    "\n",
    "    conv_mean = layers.Conv2DTranspose(filters=1,kernel_size=(3,3),strides=1,padding='valid')(conv3)\n",
    "    conv_scale = layers.Conv2DTranspose(filters=1,kernel_size=(3,3),strides=1,padding='valid')(conv3)\n",
    "    eps = tf.random.normal(shape = tf.shape(conv_mean),mean =0.0 ,stddev = 1.0, dtype = tf.float32 )\n",
    "    sample = conv_mean + eps*tf.sqrt(tf.exp(5*conv_scale))\n",
    "    model = keras.Model(inputs=z,outputs=sample,name='Generator_model')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "# def make_generator(): #### 6x6 lattices\n",
    "#     z = keras.Input(shape=(12,))\n",
    "#     hid_x1 = layers.Dense(32,activation='tanh',name='hidden_layer_1')(z)\n",
    "#     hid_x2 = layers.Dense(128,activation='tanh',name='hidden_layer_2')(hid_x1)\n",
    "#     hid_x3 = layers.Reshape((4,4,8))(hid_x2)\n",
    "#     conv_mean = layers.Conv2DTranspose(filters=1,kernel_size=(3,3),strides=1,padding='valid')(hid_x3)\n",
    "#     conv_scale = layers.Conv2DTranspose(filters=1,kernel_size=(3,3),strides=1,padding='valid')(hid_x3)\n",
    "#     eps = tf.random.normal(shape = tf.shape(conv_mean),mean =0.0 ,stddev = 1.0, dtype = tf.float32 )\n",
    "#     sample = conv_mean + eps*tf.sqrt(tf.exp(5*conv_scale))\n",
    "#     model = keras.Model(inputs=z,outputs=sample,name='Generator_model')\n",
    "#     model.summary()\n",
    "#     return model \n",
    "\n",
    "\n",
    "# def make_generator(): #### 4x4 lattices\n",
    "#     z = keras.Input(shape=(12,))\n",
    "#     hid_x1 = layers.Dense(32,activation='tanh',name='hidden_layer_1')(z)\n",
    "#     hid_x2 = layers.Dense(128,activation='tanh',name='hidden_layer_2')(hid_x1)\n",
    "#     hid_x3 = layers.Reshape((4,4,8))(hid_x2)\n",
    "#     hid_x4 = layers.Conv2DTranspose(filters = 8,kernel_size=(3,3),strides=1,padding='valid')(hid_x3)\n",
    "#     conv_mean = layers.Conv2D(filters=1,kernel_size=(3,3),strides=1,padding='valid')(hid_x4)\n",
    "#     conv_scale = layers.Conv2D(filters=1,kernel_size=(3,3),strides=1,padding='valid')(hid_x4)\n",
    "#     eps = tf.random.normal(shape = tf.shape(conv_mean),mean =0.0 ,stddev = 1.0, dtype = tf.float32 )\n",
    "#     sample = conv_mean + eps*tf.sqrt(tf.exp(5*conv_scale))\n",
    "#     model = keras.Model(inputs=z,outputs=sample,name='Generator_model')\n",
    "#     model.summary()\n",
    "#     return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_discriminator(): # 8x8 lattices\n",
    "#     input = keras.Input(shape=(l,l,2))\n",
    "#     hid_y1 = layers.Conv2D(filters=10,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer1')(periodic_padding(input,1))\n",
    "#     hid_y2 = layers.MaxPooling2D(pool_size=(2,2),padding='valid',name='layer2')(hid_y1)\n",
    "#     hid_y3 = layers.Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer3')(hid_y2)\n",
    "#     reshape_y4 = layers.Reshape((2*2*32,))(hid_y3)\n",
    "#     FC_y5 = layers.Dense(32,activation='tanh',name='Dense_layer5')(reshape_y4)\n",
    "#     FC_y6 = layers.Dense(10,activation='tanh',name='Dense_layer6')(FC_y5)\n",
    "#     output = layers.Dense(1,name='Disc_output')(FC_y6)\n",
    "#     model = keras.Model(inputs=input,outputs= output,name='Discriminator_Model')\n",
    "#     model.summary()\n",
    "#     return model\n",
    "\n",
    "\n",
    "def make_discriminator(): # 16X16 lattices\n",
    "    input = keras.Input(shape=(l,l,2))\n",
    "    hid_y1 = layers.Conv2D(filters=10,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer1')(periodic_padding(input,1))\n",
    "    hid_y2 = layers.MaxPooling2D(pool_size=(2,2),padding='valid',name='layer2')(hid_y1)\n",
    "    hid_y3 = layers.Conv2D(filters=16,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer3')(periodic_padding(hid_y2,1))\n",
    "    hid_y4 = layers.MaxPooling2D(pool_size=(2,2),padding='valid',name='layer4')(hid_y3)\n",
    "    hid_y5 = layers.Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer5')(hid_y4)\n",
    "\n",
    "    reshape_y4 = layers.Reshape((2*2*32,))(hid_y5)\n",
    "    FC_y5 = layers.Dense(32,activation='tanh',name='Dense_layer5')(reshape_y4)\n",
    "    FC_y6 = layers.Dense(20,activation='tanh',name='Dense_layer6')(FC_y5)\n",
    "    output = layers.Dense(1,name='Disc_output')(FC_y6)\n",
    "    model = keras.Model(inputs=input,outputs= output,name='Discriminator_Model')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# def make_discriminator(): # 6x6 lattices\n",
    "#     input = keras.Input(shape=(l,l,2))\n",
    "#     hid_y1 = layers.Conv2D(filters=10,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer1')(periodic_padding(input,1))\n",
    "#     hid_y2 = layers.Conv2D(filters=16,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer2')(hid_y1)\n",
    "#     hid_y3 = layers.Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer3')(hid_y2)\n",
    "\n",
    "#     reshape_y4 = layers.Reshape((2*2*32,))(hid_y3)\n",
    "#     FC_y5 = layers.Dense(32,activation='tanh',name='Dense_layer5')(reshape_y4)\n",
    "#     FC_y6 = layers.Dense(10,activation='tanh',name='Dense_layer6')(FC_y5)\n",
    "#     output = layers.Dense(1,name='Disc_output')(FC_y6)\n",
    "#     model = keras.Model(inputs=input,outputs= output,name='Discriminator_Model')\n",
    "#     model.summary()\n",
    "#     return model\n",
    "\n",
    "# def make_discriminator(): # 4x4 lattices\n",
    "#     input = keras.Input(shape=(l,l,2))\n",
    "#     hid_y1 = layers.Conv2D(filters=10,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer1')(periodic_padding(input,1))\n",
    "#     hid_y2 = layers.Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='valid',activation='tanh',name='layer2')(hid_y1)\n",
    "    \n",
    "#     reshape_y4 = layers.Reshape((2*2*32,))(hid_y2)\n",
    "#     FC_y5 = layers.Dense(32,activation='tanh',name='Dense_layer5')(reshape_y4)\n",
    "#     FC_y6 = layers.Dense(10,activation='tanh',name='Dense_layer6')(FC_y5)\n",
    "#     output = layers.Dense(1,name='Disc_output')(FC_y6)\n",
    "#     model = keras.Model(inputs=input,outputs= output,name='Discriminator_Model')\n",
    "#     model.summary()\n",
    "#     return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator()\n",
    "discriminator = make_discriminator()\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def discriminator_loss(real_output,fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output),fake_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [5000*1, 5000*2, 5000*3, 5000*4, 5000*5, 5000*6, 5000*7, 5000*8, 5000*9, 5000*10]\n",
    " \n",
    "gen_lr = 5.e-7\n",
    "dis_lr = 15.e-7\n",
    "decay  = 0.95\n",
    "values_gen = [gen_lr, gen_lr*decay, gen_lr*(decay)**2, gen_lr*(decay)**3, gen_lr*(decay)**4,\n",
    "              gen_lr*(decay)**5, gen_lr*(decay)**6, gen_lr*(decay)**7, gen_lr*(decay)**8, \n",
    "              gen_lr*(decay)**9, gen_lr*(decay)**10]\n",
    "values_dis = [dis_lr, dis_lr*decay, dis_lr*(decay)**2, dis_lr*(decay)**3, dis_lr*(decay)**4,\n",
    "              dis_lr*(decay)**5, dis_lr*(decay)**6, dis_lr*(decay)**7, dis_lr*(decay)**8, \n",
    "              dis_lr*(decay)**9, dis_lr*(decay)**10]\n",
    "learning_rate_fn_gen = keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values_gen)\n",
    "learning_rate_fn_dis = keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values_dis)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn_gen)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn_dis)\n",
    "train_G_loss = tf.keras.metrics.Mean('train_G_loss', dtype=tf.float32)\n",
    "train_D_loss = tf.keras.metrics.Mean('train_D_loss', dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x,y,tz):\n",
    "    zrand = tf.cast(np.random.normal(size=[tz.shape[0],n_zrand]),dtype = tf.float32)\n",
    "    z_rand = tf.convert_to_tensor(zrand)\n",
    "    noise = tf.concat([z_rand,tz],axis=1)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_data = tf.cast(generator(noise,training = True),dtype=tf.float32)\n",
    "        input1 = tf.concat([x,y],axis = -1)\n",
    "        input2 = tf.concat([gen_data,y],axis = -1)\n",
    "        real_output = discriminator(input1,training=True)\n",
    "        fake_output = discriminator(input2,training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output,fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))\n",
    "    train_G_loss(gen_loss)\n",
    "    train_D_loss(disc_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_directory = './cgan_samples/16x16/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt-5\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer= discriminator_optimizer,\n",
    "                                 generator = generator,\n",
    "                                 discriminator = discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for epoch in range(10):\n",
    "    \n",
    "    for step,(x,y,tz) in enumerate(training_dataset):\n",
    "        train_step(x,y,tz)\n",
    "\n",
    "    template = 'Epoch {}, Gen_Loss: {}, Disc_Loss: {}'\n",
    "    print (template.format(epoch+1,train_G_loss.result(),train_D_loss.result()))\n",
    "\n",
    "    # Reset metrics every epoch\n",
    "    train_G_loss.reset_states()\n",
    "    train_D_loss.reset_states() \n",
    "  \n",
    "stop = time.time()\n",
    "print('Time: ', stop - start)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Comparison Plots for different epochs\n",
    "lattices1=[]\n",
    "index_set = np.arange(num_classes)\n",
    "for i in index_set:\n",
    "    lattices1.append(xy_data[10000*i+5000:10000*i+6000])\n",
    "lattices1=np.array(lattices1)\n",
    "lattices1=tf.reshape(lattices1,(-1,l,l,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples_generation_for_all_temp(1000,temp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_plot(lattices1,samples,1000,0.05,2.05,num_classes,J=1,K=0,name='./cgan_samples/16x16/comparison_plot_ckpt_5_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics(lattices1,samples,0.05,2.05,num_classes,J=1,K=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('./cgan_samples/16x16/lattices_ckpt_5_6.pkl', 'wb')\n",
    "pickle.dump(samples, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
